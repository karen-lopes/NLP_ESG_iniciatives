import string
import regex as re
complete_list = [org1, org2, org3, org4, org5, org6, org7, org8, org9, org10]

def remove_non_ascii(text):
  printable = set(string.printable)
  return ''.join(filter(lambda x: x in printable, text))

def not_header(line):
  # as we're consolidating broken lines into paragraphs, we want to make sure not to include headers
  return not line.isupper()


def extract_statements(nlp, text):
  """
  Extracting ESG statements from raw text by removing junk, URLs, etc.
  We group consecutive lines into paragraphs and use spacy to parse sentences.
  """
  lines = []
  sentences = []
  # remove non ASCII characters
  text = remove_non_ascii(text)

  prev = ""
  for line in text.split('\n'):
    # aggregate consecutive lines where text may be broken down
    # only if next line starts with a space or previous does not end with dot.
    if(line.startswith(' ') or not prev.endswith('.')):
        prev = prev + ' ' + line
    else:
        # new paragraph
        lines.append(prev)
        prev = line

  # don't forget left-over paragraph
  lines.append(prev)

  # clean paragraphs from extra space, unwanted characters, urls, etc.
  # best effort clean up, consider a more versatile cleaner

  for line in lines:

      # removing header number
      line = re.sub(r'^\s?\d+(.*)$', r'\1', line)
      #removing numbers
      line= re.sub('[0-9\n]',' ',line)
      # removing trailing spaces
      line = line.strip()
      # words may be split between lines, ensure we link them back together
      line = re.sub('\s?-\s?', '-', line)
      # remove space prior to punctuation
      line = re.sub(r'\s?([,:;\.])', r'\1', line)
      # ESG contains a lot of figures that are not relevant to grammatical structure
      line = re.sub(r'\d{5,}', r' ', line)
      # remove mentions of URLs
      line = re.sub(r'((http|https)\:\/\/)?[a-zA-Z0-9\.\/\?\:@\-_=#]+\.([a-zA-Z]){2,6}([a-zA-Z0-9\.\&\/\?\:@\-_=#])*', r' ', line)
      # remove multiple spaces
      line = re.sub('\s+', ' ', line)
      #removing bbc
      line= re.sub('\WBBC',' ',line)
      # split paragraphs into well defined sentences using spacy
      for part in list(nlp(line).sents):
        sentences.append([ str(part).strip()])

  return sentences

statement_list = []
for i in range(len(complete_list)):
    company = complete_list[i][0]
    statements = extract_statements(nlp, complete_list[i][2])
    statement_list.extend(statements)
